{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b041b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sound manager...\n",
      "Sound manager initialized.\n",
      "Loading sound file: alarm.mp3\n",
      "Sound file loaded successfully.\n",
      "Loading sound file: wakeMe.mp3\n",
      "Sound file loaded successfully.\n",
      "[LOADED] 391 previous gesture samples loaded from gesture_accuracy.csv\n",
      "Running... press 'q' to quit. Keys: 1(ThumbsUp) 2(ThumbsDown) 3(OpenPalm) 4(Victory) A(accuracy) S(save CSV)\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Down\n",
      "Action for: Thumbs Down\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n",
      "Action for: Thumbs Up\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import pyautogui\n",
    "import pygame\n",
    "import csv\n",
    "from utils import calculate_ear, calculate_mar, LEFT_EYE_INDICES, RIGHT_EYE_INDICES, MOUTH_INDICES\n",
    "from sound_manager import init_sound, load_alarm, play_alarm, stop_alarm\n",
    "\n",
    "try:\n",
    "    from gesture import classify_gesture\n",
    "except ImportError:\n",
    "    print(\"Error: gesture.py missing!\")\n",
    "    exit()\n",
    "\n",
    "# INITIALIZATION\n",
    "init_sound()\n",
    "ALARM_SOUND_SLEEPY = load_alarm(\"alarm.mp3\")\n",
    "ALARM_SOUND_DROWSY = load_alarm(\"wakeMe.mp3\")\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "\n",
    "\n",
    "EAR_THRESHOLD = 0.25\n",
    "MAR_THRESHOLD = 0.5\n",
    "CONSECUTIVE_FRAMES_THRESHOLD = 30\n",
    "HEAD_TILT_THRESHOLD = -0.08\n",
    "\n",
    "last_gesture_time = 0\n",
    "GESTURE_COOLDOWN = 1.0\n",
    "\n",
    "DROWSY_FRAMES_COUNTER = 0\n",
    "is_sleepy_alarm_playing = False\n",
    "is_drowsy_alarm_playing = False\n",
    "detected_gesture = \"None\"\n",
    "\n",
    "true_labels = []   \n",
    "pred_labels = []   \n",
    "\n",
    "gesture_mapping = {\n",
    "    \"Thumbs Up\": 1,\n",
    "    \"Thumbs Down\": 2,\n",
    "    \"Open Palm\": 3,\n",
    "    \"Victory\": 4\n",
    "}\n",
    "label_to_name = {v: k for k, v in gesture_mapping.items()}\n",
    "\n",
    "try:\n",
    "    with open(\"gesture_accuracy.csv\", \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader, None)  # Skip header\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                true_labels.append(int(row[0]))\n",
    "                pred_labels.append(int(row[1]))\n",
    "\n",
    "    print(f\"[LOADED] {len(true_labels)} previous gesture samples loaded from gesture_accuracy.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"No previous gesture_accuracy.csv found. Starting fresh.\")\n",
    "\n",
    "def compute_accuracy():\n",
    "    if not true_labels:\n",
    "        return \"No accuracy data recorded yet.\"\n",
    "\n",
    "    total = len(true_labels)\n",
    "    correct = sum(1 for t, p in zip(true_labels, pred_labels) if t == p)\n",
    "    acc = (correct / total) * 100\n",
    "    matrix = np.zeros((4, 4), dtype=int)\n",
    "\n",
    "    for t, p in zip(true_labels, pred_labels):\n",
    "        if 1 <= t <= 4 and 1 <= p <= 4:\n",
    "            matrix[t-1][p-1] += 1\n",
    "\n",
    "    text = f\"\\n=== ACCURACY REPORT ===\\n\" \\\n",
    "           f\"Total Samples: {total}\\n\" \\\n",
    "           f\"Correct: {correct}\\n\" \\\n",
    "           f\"Accuracy: {acc:.2f}%\\n\\n\" \\\n",
    "           f\"Confusion Matrix (rows=true 1..4, cols=pred 1..4):\\n{matrix}\\n\"\n",
    "\n",
    "    per_class = \"\"\n",
    "    for cls in range(1, 5):\n",
    "        idxs = [i for i, t in enumerate(true_labels) if t == cls]\n",
    "        if idxs:\n",
    "            cls_correct = sum(1 for i in idxs if pred_labels[i] == cls)\n",
    "            per_class += f\"{label_to_name[cls]}: {cls_correct}/{len(idxs)} correct\\n\"\n",
    "        else:\n",
    "            per_class += f\"{label_to_name[cls]}: No samples\\n\"\n",
    "\n",
    "    return text + \"\\n\" + per_class\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Webcam could not open.\")\n",
    "    exit()\n",
    "\n",
    "prev_time = 0\n",
    "print(\"Running... press 'q' to quit. Keys: 1(ThumbsUp) 2(ThumbsDown) 3(OpenPalm) 4(Victory) A(accuracy) S(save CSV)\")\n",
    "\n",
    "# GESTURE ACTION FUNCTION\n",
    "def perform_gesture_action(gesture):\n",
    "    print(\"Action for:\", gesture)\n",
    "    if gesture == \"Thumbs Up\":\n",
    "        pyautogui.press(\"volumeup\")\n",
    "    elif gesture == \"Thumbs Down\":\n",
    "        pyautogui.press(\"volumedown\")\n",
    "    elif gesture == \"Open Palm\":\n",
    "        pyautogui.press(\"volumemute\")\n",
    "    elif gesture == \"Victory\":\n",
    "        pyautogui.press(\"nexttrack\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    display_frame = frame.copy()\n",
    "    h, w, _ = frame.shape\n",
    "    detected_gesture = \"None\"\n",
    "\n",
    "    # FPS\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - prev_time) if prev_time else 0\n",
    "    prev_time = current_time\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb_frame.flags.writeable = False\n",
    "\n",
    "    results_face = face_mesh.process(rgb_frame)\n",
    "    results_hands = hands.process(rgb_frame)\n",
    "\n",
    "    rgb_frame.flags.writeable = True\n",
    "\n",
    "    # DROWSINESS DETECTION\n",
    "    drowsy_status = \"Awake\"\n",
    "    status_color = (0, 255, 0)\n",
    "    is_sleepy = False\n",
    "    is_yawning = False\n",
    "    is_looking_down = False\n",
    "\n",
    "    if results_face.multi_face_landmarks:\n",
    "        face_landmarks = results_face.multi_face_landmarks[0].landmark\n",
    "        pixel_landmarks = np.array([(int(lm.x * w), int(lm.y * h)) for lm in face_landmarks])\n",
    "\n",
    "        avg_ear = (calculate_ear(pixel_landmarks, LEFT_EYE_INDICES) +\n",
    "                   calculate_ear(pixel_landmarks, RIGHT_EYE_INDICES)) / 2\n",
    "\n",
    "        mar = calculate_mar(pixel_landmarks, MOUTH_INDICES)\n",
    "\n",
    "        forehead_z = face_landmarks[10].z\n",
    "        chin_z = face_landmarks[152].z\n",
    "        z_diff = forehead_z - chin_z\n",
    "        is_looking_down = z_diff < HEAD_TILT_THRESHOLD\n",
    "\n",
    "        if avg_ear < EAR_THRESHOLD and not is_looking_down:\n",
    "            DROWSY_FRAMES_COUNTER += 1\n",
    "        else:\n",
    "            DROWSY_FRAMES_COUNTER = 0\n",
    "\n",
    "        if DROWSY_FRAMES_COUNTER > CONSECUTIVE_FRAMES_THRESHOLD:\n",
    "            is_sleepy = True\n",
    "\n",
    "        if mar > MAR_THRESHOLD:\n",
    "            is_yawning = True\n",
    "\n",
    "        # SLEEPY + YAWNING = HIGH ALERT\n",
    "        if is_sleepy and is_yawning:\n",
    "            drowsy_status = \"DROWSY!!\"\n",
    "            status_color = (255, 0, 255)\n",
    "\n",
    "            if is_sleepy_alarm_playing:\n",
    "                stop_alarm()\n",
    "                is_sleepy_alarm_playing = False\n",
    "\n",
    "            if not is_drowsy_alarm_playing:\n",
    "                play_alarm(ALARM_SOUND_DROWSY)\n",
    "                is_drowsy_alarm_playing = True\n",
    "\n",
    "        elif is_sleepy:\n",
    "            drowsy_status = \"SLEEPY\"\n",
    "            status_color = (0, 0, 255)\n",
    "\n",
    "            if not is_sleepy_alarm_playing:\n",
    "                play_alarm(ALARM_SOUND_SLEEPY)\n",
    "                is_sleepy_alarm_playing = True\n",
    "\n",
    "        else:\n",
    "            drowsy_status = \"Awake\"\n",
    "            status_color = (0, 255, 0)\n",
    "\n",
    "            stop_alarm()\n",
    "            is_sleepy_alarm_playing = False\n",
    "            is_drowsy_alarm_playing = False\n",
    "\n",
    "        cv2.putText(display_frame, f\"EAR: {avg_ear:.2f}\", (20, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.putText(display_frame, f\"MAR: {mar:.2f}\", (20, 120),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.putText(display_frame, f\"Yawn: {is_yawning}\", (20, 160),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.putText(display_frame, f\"Frames Closed: {DROWSY_FRAMES_COUNTER}\", (20, 200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 255), 2)\n",
    "\n",
    "        cv2.putText(display_frame, f\"Looking Down: {is_looking_down}\", (20, 240),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 165, 255), 2)\n",
    "\n",
    "\n",
    "    # HAND GESTURE DETECTION\n",
    "    if results_hands.multi_hand_landmarks:\n",
    "        for hand_landmarks in results_hands.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(display_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            gesture = classify_gesture(hand_landmarks.landmark)\n",
    "            if gesture:\n",
    "                detected_gesture = gesture\n",
    "\n",
    "                if current_time - last_gesture_time > GESTURE_COOLDOWN:\n",
    "                    perform_gesture_action(gesture)\n",
    "                    last_gesture_time = current_time\n",
    "\n",
    "    cv2.putText(display_frame, f\"FPS: {int(fps)}\", (w - 150, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.putText(display_frame, f\"STATUS: {drowsy_status}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, status_color, 3)\n",
    "\n",
    "    cv2.putText(display_frame, f\"Gesture: {detected_gesture}\", (w - 320, h - 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.putText(display_frame, \"1 : ThumbsUp 2 : ThumbsDown 3 : OpenPalm 4 : Victory  A : Acc  S : Save\", (10, h - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "\n",
    "    cv2.imshow(\"Combined Driver Monitoring System\", display_frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key in [ord('1'), ord('2'), ord('3'), ord('4')]:\n",
    "        true = int(chr(key))\n",
    "        true_labels.append(true)\n",
    "        pred = gesture_mapping.get(detected_gesture, 0)  \n",
    "        pred_labels.append(pred)\n",
    "        print(f\"[RECORDED] True={true} ({label_to_name[true]}), Pred={pred} ({detected_gesture})\")\n",
    "\n",
    "    elif key == ord('a') or key == ord('A'):\n",
    "        print(compute_accuracy())\n",
    "\n",
    "    elif key == ord('s') or key == ord('S'):\n",
    "        file_exists = False\n",
    "        try:\n",
    "            with open(\"gesture_accuracy.csv\", \"r\") as f:\n",
    "                file_exists = True\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        with open(\"gesture_accuracy.csv\", \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            if not file_exists:\n",
    "                writer.writerow([\"True\", \"Predicted\"])\n",
    "\n",
    "            for t, p in zip(true_labels, pred_labels):\n",
    "                writer.writerow([t, p])\n",
    "        print(\"Appended new samples to: gesture_accuracy.csv\")\n",
    "\n",
    "    elif key == ord('q') or key == ord('Q'):\n",
    "        break\n",
    "\n",
    "stop_alarm()\n",
    "cap.release()\n",
    "face_mesh.close()\n",
    "hands.close()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
